{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOEYi6NkXnx9",
        "outputId": "ee9743bd-8082-428d-e558-e57eea5a5f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymFsvZeJV7rT",
        "outputId": "6890f33f-2e77-43c5-c0fa-cd2feb6aed4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/nltkdata/brown-corpus?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.29M/9.29M [00:00<00:00, 86.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/nltkdata/brown-corpus/versions/3\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"nltkdata/brown-corpus\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "brown_words = brown.words()\n",
        "tokens = [word.lower() for word in brown_words]\n",
        "tokens = [word for word in tokens if word not in string.punctuation]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "print(\"Preprocessed text sample:\", tokens[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YslIcxtWesg",
        "outputId": "306c5e2d-7bc5-49ed-f169-1a75df2a7254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed text sample: ['fulton', 'county', 'grand', 'jury', 'said', 'friday', 'investigation', \"atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'evidence', \"''\", 'irregularities', 'took', 'place', 'jury', 'said', 'term-end', 'presentments', 'city', 'executive', 'committee', 'over-all', 'charge', 'election', '``', 'deserves', 'praise', 'thanks', 'city', 'atlanta', \"''\", 'manner', 'election', 'conducted', 'september-october', 'term', 'jury', 'charged', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'investigate', 'reports']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "\n",
        "unigrams = tokens\n",
        "bigrams = list(ngrams(tokens, 2))\n",
        "trigrams = list(ngrams(tokens, 3))\n",
        "quadgrams = list(ngrams(tokens, 4))\n",
        "\n",
        "unigram_counts = Counter(unigrams)\n",
        "bigram_counts = Counter(bigrams)\n",
        "trigram_counts = Counter(trigrams)\n",
        "quadgram_counts = Counter(quadgrams)\n",
        "\n",
        "print(\"Unigram sample:\", list(unigram_counts.items())[:5])\n",
        "print(\"Bigram sample:\", list(bigram_counts.items())[:5])\n",
        "print(\"Trigram sample:\", list(trigram_counts.items())[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4npiibboYUfB",
        "outputId": "67d7b96a-7ff1-48fc-8ee6-b24477289d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram sample: [('fulton', 17), ('county', 155), ('grand', 48), ('jury', 67), ('said', 1961)]\n",
            "Bigram sample: [(('fulton', 'county'), 6), (('county', 'grand'), 1), (('grand', 'jury'), 10), (('jury', 'said'), 9), (('said', 'friday'), 4)]\n",
            "Trigram sample: [(('fulton', 'county', 'grand'), 1), (('county', 'grand', 'jury'), 1), (('grand', 'jury', 'said'), 1), (('jury', 'said', 'friday'), 1), (('said', 'friday', 'investigation'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def probability_ngram(ngram, ngram_counts, total_ngrams):\n",
        "    return ngram_counts[ngram] / total_ngrams\n",
        "\n",
        "total_unigrams = sum(unigram_counts.values())\n",
        "total_bigrams = sum(bigram_counts.values())\n",
        "total_trigrams = sum(trigram_counts.values())\n",
        "total_quadgrams = sum(quadgram_counts.values())\n",
        "\n",
        "print(\"Total unigrams:\", total_unigrams)\n",
        "print(\"Total bigrams:\", total_bigrams)\n",
        "print(\"Total trigrams:\", total_trigrams)\n",
        "\n",
        "\n",
        "sample_bigram = ('linear', 'algebra')\n",
        "sample_prob = probability_ngram(sample_bigram, bigram_counts, total_bigrams)\n",
        "\n",
        "print(f\"Probability of {sample_bigram}: {sample_prob}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI6oz7QAYlB7",
        "outputId": "9cbf6292-b315-4975-da7d-b3dab9556cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unigrams: 557984\n",
            "Total bigrams: 557983\n",
            "Total trigrams: 557982\n",
            "Probability of ('linear', 'algebra'): 3.5843385909606566e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def laplace_smoothing(ngram, ngram_counts, total_ngrams, vocab_size):\n",
        "    return (ngram_counts[ngram] + 1) / (total_ngrams + vocab_size)\n",
        "\n",
        "vocab_size = len(unigram_counts)\n",
        "\n",
        "sample_prob_smooth = laplace_smoothing(sample_bigram, bigram_counts, total_bigrams, vocab_size)\n",
        "\n",
        "print(f\"Smoothed probability of {sample_bigram}: {sample_prob_smooth}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGfvsZaZYxdc",
        "outputId": "596c5ae9-fe65-4f6b-8b9d-b03c265819cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoothed probability of ('linear', 'algebra'): 4.937426350056945e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Function for Unigram Model (Random words)\n",
        "def generate_unigram_sentence(unigram_counts, length=10):\n",
        "    words = list(unigram_counts.keys())\n",
        "    return ' '.join(random.choices(words, k=length))\n",
        "\n",
        "# Function for Bigram Model (Word pairs based on probability)\n",
        "def generate_bigram_sentence(bigram_counts, length=10):\n",
        "    sentence = [random.choice(list(bigram_counts.keys()))[0]]\n",
        "    for _ in range(length - 1):\n",
        "        prev_word = sentence[-1]\n",
        "        candidates = [pair[1] for pair in bigram_counts.keys() if pair[0] == prev_word]\n",
        "        sentence.append(random.choice(candidates) if candidates else random.choice(list(unigram_counts.keys())))\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "# Function for Trigram Model (Word triples based on probability)\n",
        "def generate_trigram_sentence(trigram_counts, length=10):\n",
        "    sentence = list(random.choice(list(trigram_counts.keys())))\n",
        "    while len(sentence) < length:\n",
        "        prev_bigram = tuple(sentence[-2:])  # Last two words\n",
        "        candidates = [trigram[2] for trigram in trigram_counts.keys() if trigram[:2] == prev_bigram]\n",
        "        sentence.append(random.choice(candidates) if candidates else random.choice(list(unigram_counts.keys())))\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "def generate_quadgram_sentence(quadgrams_counts, length=10):\n",
        "    sentence = list(random.choice(list(quadgrams_counts.keys())))\n",
        "    while len(sentence) < length:\n",
        "        prev_trigram = tuple(sentence[-3:])  # Last two words\n",
        "        candidates = [quadgrams[3] for quadgrams in quadgrams_counts.keys() if quadgrams[:3] == prev_trigram]\n",
        "        sentence.append(random.choice(candidates) if candidates else random.choice(list(unigram_counts.keys())))\n",
        "    return ' '.join(sentence)\n",
        "\n",
        "\n",
        "unigram_sentence1 = generate_unigram_sentence(unigram_counts)\n",
        "unigram_sentence2 = generate_unigram_sentence(unigram_counts)\n",
        "unigram_sentence3 = generate_unigram_sentence(unigram_counts)\n",
        "unigram_sentence4 = generate_unigram_sentence(unigram_counts)\n",
        "unigram_sentence5 = generate_unigram_sentence(unigram_counts)\n",
        "\n",
        "bigram_sentence1 = generate_bigram_sentence(bigram_counts)\n",
        "bigram_sentence2 = generate_bigram_sentence(bigram_counts)\n",
        "bigram_sentence3 = generate_bigram_sentence(bigram_counts)\n",
        "bigram_sentence4 = generate_bigram_sentence(bigram_counts)\n",
        "bigram_sentence5 = generate_bigram_sentence(bigram_counts)\n",
        "\n",
        "trigram_sentence1 = generate_trigram_sentence(trigram_counts)\n",
        "trigram_sentence2 = generate_trigram_sentence(trigram_counts)\n",
        "trigram_sentence3 = generate_trigram_sentence(trigram_counts)\n",
        "trigram_sentence4 = generate_trigram_sentence(trigram_counts)\n",
        "trigram_sentence5 = generate_trigram_sentence(trigram_counts)\n",
        "\n",
        "quadgram_sentence1 = generate_quadgram_sentence(quadgram_counts)\n",
        "quadgram_sentence2 = generate_quadgram_sentence(quadgram_counts)\n",
        "quadgram_sentence3 = generate_quadgram_sentence(quadgram_counts)\n",
        "quadgram_sentence4 = generate_quadgram_sentence(quadgram_counts)\n",
        "quadgram_sentence5 = generate_quadgram_sentence(quadgram_counts)\n",
        "\n",
        "print(\"Unigram Sentence 1:\", unigram_sentence1)\n",
        "print(\"Unigram Sentence 2:\", unigram_sentence2)\n",
        "print(\"Unigram Sentence 3:\", unigram_sentence3)\n",
        "print(\"Unigram Sentence 4:\", unigram_sentence4)\n",
        "print(\"Unigram Sentence 5:\", unigram_sentence5)\n",
        "\n",
        "print(\"Bigram Sentence 1:\", bigram_sentence1)\n",
        "print(\"Bigram Sentence 2:\", bigram_sentence2)\n",
        "print(\"Bigram Sentence 3:\", bigram_sentence3)\n",
        "print(\"Bigram Sentence 4:\", bigram_sentence4)\n",
        "print(\"Bigram Sentence 5:\", bigram_sentence5)\n",
        "\n",
        "print(\"Trigram Sentence 1:\", trigram_sentence1)\n",
        "print(\"Trigram Sentence 2:\", trigram_sentence2)\n",
        "print(\"Trigram Sentence 3:\", trigram_sentence3)\n",
        "print(\"Trigram Sentence 4:\", trigram_sentence4)\n",
        "print(\"Trigram Sentence 5:\", trigram_sentence5)\n",
        "\n",
        "print(\"Quadgram Sentence 1:\", quadgram_sentence1)\n",
        "print(\"Quadgram Sentence 2:\", quadgram_sentence2)\n",
        "print(\"Quadgram Sentence 3:\", quadgram_sentence3)\n",
        "print(\"Quadgram Sentence 4:\", quadgram_sentence4)\n",
        "print(\"Quadgram Sentence 5:\", quadgram_sentence5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGK5yH_WZ5cM",
        "outputId": "d3646cbc-1f83-4051-cbe9-7a296c8beece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Sentence 1: severna newman extractor colquitt burne 695 featured race-driver no-one brim\n",
            "Unigram Sentence 2: 350 fille neonatal forearms civilizing compositions ted crafts spattered plaques\n",
            "Unigram Sentence 3: drown inhibition chattered belle imperiled much-craved reverse hull smoothbore peed\n",
            "Unigram Sentence 4: anglophobia 607-608 rumen epicurus low-foam l impertinent spirit-gum non-commissioned conceiving\n",
            "Unigram Sentence 5: prussia tangy offer warmed 70 rodent thimble dawning bathrooms glottochronological\n",
            "Bigram Sentence 1: additional eleven mines protection forage commercial sources scholars really failing\n",
            "Bigram Sentence 2: leave sequence relationships wives expression anti-catholicism first ball tickets back\n",
            "Bigram Sentence 3: swarthy complexion pale chest bubble bauble '' crucial difference present\n",
            "Bigram Sentence 4: quarters -- soirees fox chapel assembly make computations set marginal\n",
            "Bigram Sentence 5: wants '' squire '' poems 1912 united coddington running object\n",
            "Trigram Sentence 1: buy american act urge congress reenact rider task providing reasonable\n",
            "Trigram Sentence 2: obtain junior senior mrs. walter monroe bridegroom's parents barrett wendells\n",
            "Trigram Sentence 3: season banish spoilage wake new affluence new techniques processing comes\n",
            "Trigram Sentence 4: 2 7th cavalry best fighting condition entire complement non-commissioned officers\n",
            "Trigram Sentence 5: solids membrane filter yielded average effluent containing 20 mg/l aj\n",
            "Quadgram Sentence 1: given instance notwithstanding amount forethought calculation however elaborate thus theory\n",
            "Quadgram Sentence 2: american seamen ready times serve nation cause freedom justice testimony\n",
            "Quadgram Sentence 3: holy sacred road integration jazz like sex mystique substitute sex\n",
            "Quadgram Sentence 4: time panelized utilizes standard materials requires use simple tools following\n",
            "Quadgram Sentence 5: amy melisande congdon real aunt positively monumental best gibson girl\n"
          ]
        }
      ]
    }
  ]
}